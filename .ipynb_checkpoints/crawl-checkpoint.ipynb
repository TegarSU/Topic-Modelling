{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer_key = 'mniJ4xlW8hlfvFxWyYkvm6TAm'\n",
    "# consumer_secret = 'XKa1i8HfuWl925CcLajdLnmVOCMXWq4xMhLubHAzzwMqaKA6eZ'\n",
    "# access_token = '3063908508-S7KI9scFpuD99aOT0iQEC1Xb7jLIjAb3zwSVVEI'\n",
    "# access_token_secret = 'Bi2LnIebB7lYRkWdxMlvzvGxU8twJ8NqoQvoeVVDILSlo'\n",
    "# # OAuth process, using the keys and tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_token_secret)\n",
    "# api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat = \"-6.265750\" #latitude\n",
    "# long = \"106.78182\" #longitude\n",
    "# trends = api.trends_closest(lat, long) #search WOEID jakarta\n",
    "\n",
    "# trends = api.trends_place(1047378) # search by WOEID, jakarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#SemogaPuasaTahunIni', '#AlasanTetapHidup', '#BucinWowoCaper', '#DiskualifikasiYangCurang', '#sekolahnaiktransjakarta', 'Favorite MV', 'Sheyla', 'Mas AHY', 'Wonu', 'Partai Demokrat']\n"
     ]
    }
   ],
   "source": [
    "# trends\n",
    "data = trends[0] \n",
    "trends = data['trends']\n",
    "trending = list() #trending\n",
    "names = [trend['name'] for trend in trends]\n",
    "\n",
    "for i in range(10):\n",
    "    trending.append(names[i]) #get 10 trending\n",
    "\n",
    "# trending  \n",
    "\n",
    "print(trending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # type(trending)\n",
    "# max_tweets = 1000\n",
    "# # latitide = \"-6.265750\" #latitude\n",
    "# # longitude = \"106.78182\"\n",
    "# # radius = \"150km\"\n",
    "# query=\"Partai Demokrat\"\n",
    "# # for i in trending:\n",
    "# searched_tweets = [status for status in tweepy.Cursor(api.search, q=query).items(max_tweets)]\n",
    "# #     tweet = api.search(q, lang, locale, rpp, page, since_id, geocode, show_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,v in enumerate(searched_tweets):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('topik_03.csv', 'w', encoding=\"utf-8\",newline='') as csv_tweet:\n",
    "\n",
    "#     fieldnames_tweet = ['id', 'user_name', 'created_at', 'text','trendings']\n",
    "#     writer_tweet = csv.DictWriter(csv_tweet, fieldnames=fieldnames_tweet)\n",
    "#     writer_tweet.writeheader()\n",
    "\n",
    "#     for tweet in searched_tweets:\n",
    "# #         if \"http\" not in tweet.text and \"@\" not in tweet.text:\n",
    "#             #line = re.sub(\"[^A-Za-z]\", \" \", tweet.text)\n",
    "#             #user_id = tweet.user.id\n",
    "#         writer_tweet.writerow({\n",
    "#             'id': tweet.id, \n",
    "#             'user_name': tweet.user.screen_name,\n",
    "#             'created_at': tweet.created_at, \n",
    "#             'text': tweet.text,\n",
    "#             'trendings': query\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"topik_01.csv\")\n",
    "data2 = pd.read_csv(\"topik_02.csv\")\n",
    "data3 = pd.read_csv(\"topik_03.csv\")\n",
    "\n",
    "frame = [data1,data2,data3]\n",
    "data = pd.concat(frame)\n",
    "\n",
    "# data\n",
    "# text = data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "\n",
    "    pattern = re.compile(r\"[\\n]\")\n",
    "    patterns = re.compile(r'\\s+')\n",
    "    sentence = re.sub(pattern, ' ', text)\n",
    "    sentence = re.sub(patterns, ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(normalize)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.to_csv(\"C:/Users/USER/Downloads/tegar nitip/SMT 8/AMS/FP/all.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>trendings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123983568500400129</td>\n",
       "      <td>me_idy</td>\n",
       "      <td>2019-05-02 16:12:19</td>\n",
       "      <td>#SemogaPuasaTahunIni nggak sendiri lagi.. Tapi, itu cuma ekspetasi ðŸ˜• Kenyataannya... Masih JOMBLO!! https://t.co/3TcbJrO8M4</td>\n",
       "      <td>#SemogaPuasaTahunIni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1123983419283845125</td>\n",
       "      <td>robbseptiants</td>\n",
       "      <td>2019-05-02 16:11:44</td>\n",
       "      <td>#SemogaPuasaTahunIni bisa tahan godaan dari orngÂ², liar, nakal, brutal membuat orang menjadi gempar.</td>\n",
       "      <td>#SemogaPuasaTahunIni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123983321787195393</td>\n",
       "      <td>natamiayunda</td>\n",
       "      <td>2019-05-02 16:11:21</td>\n",
       "      <td>RT @gryprmna: #SemogaPuasaTahunIni kaga mikirin people we can't have terooos</td>\n",
       "      <td>#SemogaPuasaTahunIni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123983291210539008</td>\n",
       "      <td>AlFathirAU__</td>\n",
       "      <td>2019-05-02 16:11:13</td>\n",
       "      <td>#SemogaPuasaTahunIni disehatkan mental dan jasmani, berubah sedikit ke arah yang lebih baik. Aaminn</td>\n",
       "      <td>#SemogaPuasaTahunIni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1123983249364090881</td>\n",
       "      <td>Feriikrnwn_</td>\n",
       "      <td>2019-05-02 16:11:03</td>\n",
       "      <td>#SemogaPuasaTahunIni bukber nya ga wacana semuaa</td>\n",
       "      <td>#SemogaPuasaTahunIni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      user_name           created_at  \\\n",
       "0  1123983568500400129  me_idy         2019-05-02 16:12:19   \n",
       "1  1123983419283845125  robbseptiants  2019-05-02 16:11:44   \n",
       "2  1123983321787195393  natamiayunda   2019-05-02 16:11:21   \n",
       "3  1123983291210539008  AlFathirAU__   2019-05-02 16:11:13   \n",
       "4  1123983249364090881  Feriikrnwn_    2019-05-02 16:11:03   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0  #SemogaPuasaTahunIni nggak sendiri lagi.. Tapi, itu cuma ekspetasi ðŸ˜• Kenyataannya... Masih JOMBLO!! https://t.co/3TcbJrO8M4   \n",
       "1  #SemogaPuasaTahunIni bisa tahan godaan dari orngÂ², liar, nakal, brutal membuat orang menjadi gempar.                          \n",
       "2  RT @gryprmna: #SemogaPuasaTahunIni kaga mikirin people we can't have terooos                                                  \n",
       "3  #SemogaPuasaTahunIni disehatkan mental dan jasmani, berubah sedikit ke arah yang lebih baik. Aaminn                           \n",
       "4  #SemogaPuasaTahunIni bukber nya ga wacana semuaa                                                                              \n",
       "\n",
       "              trendings  \n",
       "0  #SemogaPuasaTahunIni  \n",
       "1  #SemogaPuasaTahunIni  \n",
       "2  #SemogaPuasaTahunIni  \n",
       "3  #SemogaPuasaTahunIni  \n",
       "4  #SemogaPuasaTahunIni  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"all.csv\")\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
